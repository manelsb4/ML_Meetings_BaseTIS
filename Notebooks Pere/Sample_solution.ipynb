{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: ML para predecir la Supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook es una guía a seguir para generar y utilizar un algoritmo de ML (**M**achine **L**earning) en la predicción de datos. \n",
    "\n",
    "En concreto, nuestro objetivo será realizar una clasificación binaria de la supervivencia o no de la gente que había a bordo del titanic en su hundimiento (**0**: La persona no sobrevive al hundimiento del titanic; **1**: sí que sobrevive). Basaremos esta clasificación en diferentes datos referentes a los ocupantes del barco (Referirse a la página: https://www.kaggle.com/c/titanic/data para obtener información sobre los campos de nuestras tablas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Paso: Cargamos los Datos en tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este primer paso, utilizaremos una librería muy útil de python, con varias funciones interesantes que ya vienen implementadas: Pandas.\n",
    "\n",
    "Tenemos que cargar 2 datasets, uno que nos servirá para entrenar nuestro modelo, que contendrá la variable que queremos predecir; y otro que servirá para probar el modelo y cuyos resultados tendremos que subir a la competición Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importamos librerias necesarias\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "path = 'C:/Users/felix.hernandez/Desktop/Datathon_II/'\n",
    "\n",
    "# Cargamos los dos sets de datos en dos Dataframes de Pandas.\n",
    "test_df = pd.read_csv(path + 'test.csv', sep = ',')\n",
    "train_df = pd.read_csv(path + 'train.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de movernos un poco por los datasets para familarizarnos con ellos. Normalmente, el *testing dataset* (usado para probar el modelo) tendrá una columna menos que el *training dataset* (el usado para entrenar el modelo), que será nuestra variable/columna **Objectivo** (o **Target**). Vamos a ver cuál es en nuestro caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las columnas presentes en ambos datasets son: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked \n",
      "\n",
      "Nuestra(s) variable(s) objetivo es: Survived\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos la lista de nombres de columna en el training y testing datasets\n",
    "tr_c = train_df.columns\n",
    "te_c = test_df.columns\n",
    "\n",
    "# Buscamos diferencias entre las columnas: 2 formas de hacerlo\n",
    "#target = []\n",
    "#for col in tr_c:\n",
    "#    if col not in te_c:\n",
    "#        target.append(col)\n",
    "        \n",
    "# Manera más fácil, corta y rápida, la más \"pythonica\" :)\n",
    "target = set(tr_c) - set(te_c)\n",
    "\n",
    "print 'Las columnas presentes en ambos datasets son: %s \\n' % (', '.join(tr_c))\n",
    "print 'Nuestra(s) variable(s) objetivo es: %s' % (', '.join(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entrenar un modelo de ML, hay que tener en cuenta dos cosas principalmente: \n",
    "\n",
    "1. Hay que diferenciar entre **features**, características o variables del modelo (las que se usan para predecir) y **target variable** que sería la variable a predecir\n",
    "\n",
    "2. Nuestras *features* pueden ser de dos tipos: **Numéricas**, **Categóricas** o **Ordinales**. Diferencias entre estas variables:\n",
    " 2. **Categóricas**: Tienen varias categorías (como su nombre indica) y cada  valor de la variable está dentro de una de estas categorías. No tiene sentido calcular medias o máximos/mínimos con ellas, pero sí calcular la frecuencia de aparición de cada categoría (por ejemplo)\n",
    " 2. **Numéricas**: Pueden ser *continuas* o *discretas*. Toman valores numéricos entre un máximo y un mínimo. Con ellas tiene sentido calcular máximos, mínimos, medias... \n",
    " 2. **Ordinales**: Son similares a las variables categóricas, pero tienen un orden relativo entre ellas. Suelen tomar valores numéricos discretos (como su nombre indica)\n",
    "    \n",
    "Es el momento de visualizar los datos, para ver la pinta que tienen y sacar algunas conclusiones. Tenemos dos maneras de ver nuestros *Dataframes*: el método *sample(lineas_a_mostrar)*, o el método *head(lineas_a_mostrar)*. Usaremos el método sample() ya que la visualización es un poco mejor y comentaremos el otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moor, Mrs. (Beila)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392096</td>\n",
       "      <td>12.475</td>\n",
       "      <td>E121</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Davies, Mr. Alfred J</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 48871</td>\n",
       "      <td>24.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleaver, Miss. Alice</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>806</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johansson, Mr. Karl Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347063</td>\n",
       "      <td>7.775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                          Name     Sex  \\\n",
       "297          298         0       1  Allison, Miss. Helen Loraine  female   \n",
       "823          824         1       3            Moor, Mrs. (Beila)  female   \n",
       "565          566         0       3          Davies, Mr. Alfred J    male   \n",
       "708          709         1       1          Cleaver, Miss. Alice  female   \n",
       "805          806         0       3     Johansson, Mr. Karl Johan    male   \n",
       "\n",
       "      Age  SibSp  Parch     Ticket     Fare    Cabin Embarked  \n",
       "297   2.0      1      2     113781  151.550  C22 C26        S  \n",
       "823  27.0      0      1     392096   12.475     E121        S  \n",
       "565  24.0      2      0  A/4 48871   24.150      NaN        S  \n",
       "708  22.0      0      0     113781  151.550      NaN        S  \n",
       "805  31.0      0      0     347063    7.775      NaN        S  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_df.dtypes\n",
    "\n",
    "train_df.sample(n=5)\n",
    "\n",
    "# train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta visualización podemos sacar algunas conclusiones:\n",
    "* **Features Numéricas**: Age (continua), Fare(continua), SibSp(Discrete), Parch(Discrete)\n",
    "* **Features Categóricas**: Survived, Sex, Embarked, Pclass. También podriamos incluir Ticket y Cabin, aunque realmente no tienen pinta de ser categorías si no un *carácter alfanumérico* (viendo esto podemos empezar a suponer que no son demasiado significativas para nosotros, pero lo veremos más adelante)\n",
    "\n",
    "También nos hacemos una idea del tipo que son cada una de nuestras variables:\n",
    "* Survived: int\n",
    "* Pclass: int \n",
    "* Name: string\n",
    "* Sex: string\n",
    "* Age: float\n",
    "* SibSp: int\n",
    "* Parch: int\n",
    "* Ticket: string\n",
    "* Fare: float\n",
    "* Cabin: string\n",
    "* Embarked: string\n",
    "\n",
    "También podemos llevar a cabo un análisis estadístico de nuestros datasets con el comando usado previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de pasajeros en nuestro Training Dataset es de: 891 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graham, Mr. George Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                       Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                        891   891   \n",
       "unique          NaN         NaN         NaN                        891     2   \n",
       "top             NaN         NaN         NaN  Graham, Mr. George Edward  male   \n",
       "freq            NaN         NaN         NaN                          1   577   \n",
       "mean     446.000000    0.383838    2.308642                        NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                        NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                        NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                        NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                        NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                        NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                        NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch    Ticket        Fare        Cabin  \\\n",
       "count   714.000000  891.000000  891.000000       891  891.000000          204   \n",
       "unique         NaN         NaN         NaN       681         NaN          147   \n",
       "top            NaN         NaN         NaN  CA. 2343         NaN  C23 C25 C27   \n",
       "freq           NaN         NaN         NaN         7         NaN            4   \n",
       "mean     29.699118    0.523008    0.381594       NaN   32.204208          NaN   \n",
       "std      14.526497    1.102743    0.806057       NaN   49.693429          NaN   \n",
       "min       0.420000    0.000000    0.000000       NaN    0.000000          NaN   \n",
       "25%      20.125000    0.000000    0.000000       NaN    7.910400          NaN   \n",
       "50%      28.000000    0.000000    0.000000       NaN   14.454200          NaN   \n",
       "75%      38.000000    1.000000    0.000000       NaN   31.000000          NaN   \n",
       "max      80.000000    8.000000    6.000000       NaN  512.329200          NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'El número de pasajeros en nuestro Training Dataset es de: %s \\n' % (train_df.shape[0])\n",
    "\n",
    "train_df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a este resumen estadístico, podemos sacar varias conclusiones:\n",
    "\n",
    "* Tenemos un total de 891 pasajeros en nuestro training dataset.\n",
    "* Hay algunas variables que no están informadas para todos los pasajeros:\n",
    "    * **Age**: $\\frac{(891-714)}{891} \\times 100 = 19.8$% de campos no informados\n",
    "    * **Cabin**: $\\frac{(891-204)}{891} \\times 100 = 77.1$% de campos no informados\n",
    "    * **Embarked**: $\\frac{(891-889)}{891} \\times 100 = 0.22$% de campos no informados\n",
    " \n",
    "Como hemos visto, nos hemos centrado sobretodo en investigar los valores nulos. ¿Por qué? Sencillamente porque son los valores que más problemas dan a la hora de entrenar un modelo de ML. La mejor manera de ver los valores nulos es comprobar si són nulos y contar los que lo sean usando pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de nulos por campo en la dataframe de entrenamiento \n",
      "\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64 \n",
      "\n",
      "Número de nulos por campo en la dataframe de test \n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print 'Número de nulos por campo en la dataframe de entrenamiento \\n'\n",
    "print pd.isnull(train_df).sum(), '\\n'\n",
    "print 'Número de nulos por campo en la dataframe de test \\n'\n",
    "print test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacernos una idea de lo importantes que son nuestras features analizando en detalle su relación con nuestra variable objetivo. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de mujeres que sobrevivieron fue de: 74.2% \n",
      "\n",
      "El porcentaje de hombres que sobrevivieron fue de 18.89% \n",
      "\n",
      "El porcentaje de pasajeros con Pclass = 1 que sobrevivieron fue de: 62.96% \n",
      "\n",
      "El porcentaje de pasajeros con Pclass = 2 que sobrevivieron fue de: 47.28% \n",
      "\n",
      "El porcentaje de pasajeros con Pclass = 3 que sobrevivieron fue de: 24.24% \n",
      "\n",
      "El porcentaje de pasajeros con camarote informado que sobrevivieron fue de:    66.67% \n",
      "\n",
      "El porcentaje de pasajeros con camarote no informado que sobrevivieron fue de: 29.99% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "######################## Para el SEXO ##########################\n",
    "################################################################\n",
    "\n",
    "# Mujeres que sobreviven:\n",
    "# w_s = (train_df['Survived'][train_df.Sex == 'female'] == 1).count() \n",
    "\n",
    "# El método value_couns nos devuelve un cuent para cada valor de la columna seleccionada \n",
    "w_s = train_df['Survived'][train_df.Sex == 'female'].value_counts(normalize = True)[1]\n",
    "\n",
    "# Hombres que sobreviven:\n",
    "m_s = train_df['Survived'][train_df.Sex == 'male'].value_counts(normalize = True)[1]\n",
    "\n",
    "print 'El porcentaje de mujeres que sobrevivieron fue de: {0}% \\n'.format((w_s*100).round(2))\n",
    "print 'El porcentaje de hombres que sobrevivieron fue de {0}% \\n'.format((m_s*100).round(2))\n",
    "\n",
    "\n",
    "################################################################\n",
    "######################## Para Pclass ###########################\n",
    "################################################################\n",
    "\n",
    "# Tenemos tres valores para esta variable: 1, 2 y 3:\n",
    "p_1 = train_df['Survived'][train_df.Pclass == 1].value_counts(normalize = True)[1]\n",
    "p_2 = train_df['Survived'][train_df.Pclass == 2].value_counts(normalize = True)[1]\n",
    "p_3 = train_df['Survived'][train_df.Pclass == 3].value_counts(normalize = True)[1]\n",
    "\n",
    "print 'El porcentaje de pasajeros con Pclass = 1 que sobrevivieron fue de: {0}% \\n'.format((p_1*100).round(2))\n",
    "print 'El porcentaje de pasajeros con Pclass = 2 que sobrevivieron fue de: {0}% \\n'.format((p_2*100).round(2))\n",
    "print 'El porcentaje de pasajeros con Pclass = 3 que sobrevivieron fue de: {0}% \\n'.format((p_3*100).round(2))\n",
    "\n",
    "\n",
    "################################################################\n",
    "########### Para Cabin (Informado o no informado) ##############\n",
    "################################################################\n",
    "\n",
    "# Crearemos una nueva variable CabinInf, un booleano que nos indicará si el pasajero\n",
    "# tenía la cabina informada o no.\n",
    "train_df['CabinInf'] = train_df.Cabin.notnull().astype(int) \n",
    "test_df['CabinInf'] = test_df.Cabin.notnull().astype(int)\n",
    "\n",
    "inf_s = train_df[train_df['CabinInf'] == 1].Survived.value_counts(normalize = True)[1]\n",
    "noinf_s = train_df[train_df['CabinInf'] == 0].Survived.value_counts(normalize = True)[1]\n",
    "\n",
    "print 'El porcentaje de pasajeros con camarote informado que sobrevivieron fue de:    {0}% \\n'.format((inf_s*100).round(2))\n",
    "print 'El porcentaje de pasajeros con camarote no informado que sobrevivieron fue de: {0}% \\n'.format((noinf_s*100).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, en la última parte de la celda anterior hemos creado una nueva columna para estudiar el campo *Cabina*. Esta es una técnica bastante utilizada en ML cuando nos encontramos con campos con una gran cantidad de registros nulos, y que suele dar bastante buenos resultados.\n",
    "\n",
    "Ahora que ya nos hemos hecho una idea de lo relacionadas que pueden estar nuestras variables a nuestra variable objetivo, vamos a **Limpiar los Datos** para poder entrenar nuestro modelo sin problemas.\n",
    "\n",
    "Uno de los problemas más comunes es el tratamiento de los valores **nulos** dentro de nuestros datos. La mayoría de los modelos de ML no saben tratar los valores nulos, o sea que hay que idear una manera de tratar con ellos. Recordemos que tenemos 3 campos con valores nulos: Embarked (2 nulos), Age (177 nulos) y Cabin (687 nulos). Vamos a ver como tratar con ellos:\n",
    "\n",
    "**IMPORTANTE**: Todos los cambios que se realicen en la Dataframe de **Train**, también deben realizarse en la df de **Test**!! \n",
    "Las dos dataframes deben ser iguales para que nuestro modelo pueda trabajar con ellas (mismas features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############################### EMBARKED ###################################\n",
    "############################################################################\n",
    "\n",
    "# Miramos cual és el puerto (de los 3 posibles) en el que embarca más gente\n",
    "ports = train_df.groupby('Embarked'). count().PassengerId\n",
    "# Puesto que hay 644 personas que embarcan en Southampton, podemos assignar los\n",
    "# valores nulos a este puerto\n",
    "# train_df.Embarked = train_df.Embarked.fillna('S')\n",
    "train_df = train_df.fillna({'Embarked' : 'S'})\n",
    "\n",
    "############################################################################\n",
    "############################### CABIN ######################################\n",
    "############################################################################\n",
    "# Podemos hacer dos cosas con esta feature#: \n",
    "#     1 - O bien no la consideramos (no aporta casi información)\n",
    "#     2 - Podemos utilizar el Booleano de antes (Informado o no)\n",
    "# De momento no la consideramos, podemos probar a añadirla y ver si mejoran resultados\n",
    "train_df.drop(['Cabin', 'CabinInf'], axis = 1, inplace = True)\n",
    "test_df.drop(['Cabin', 'CabinInf'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df\n",
    "############################################################################\n",
    "############################### Age ########################################\n",
    "############################################################################\n",
    "# Para la edad es más difícil llenar huecos, ya que tenemos bastantes nulos. Cosas a tener en cuenta:\n",
    "#    1. No podemos quitarla porque parece bastante significativa\n",
    "#    2. No podemos usar la media para rellenar la edad, ya que no podemos asignarle a un niño\n",
    "#       o a una persona mayor la media, que es de 29.699\n",
    "\n",
    "# Presentaremos 2 propuestas. Cualquiera de las dos puede ser utilizada:\n",
    "#    1. Agrupar en función del prefijo del nombre (Mr, Dr, Lady,...) y asignar el valor\n",
    "#       de la media del grupo.\n",
    "#    2. Usar crear una nueva variable que agrupe según el prefijo del nombre y no utilizar\n",
    "#       la variable Age\n",
    "\n",
    "# ------------------------------ PROPUESTA 1 ------------------------------------\n",
    "train_df['Titulo'] = train_df.Name.str.extract('([A-Za-z]+)\\.', expand = False) # extraer Prefijo\n",
    "test_df['Titulo'] = test_df.Name.str.extract('([A-Za-z]+)\\.', expand = False) # extraer Prefijo\n",
    "    \n",
    "# Vemos que hay algunos prefijos que no están bien escritos. Los corregimos:\n",
    "train_df['Titulo'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "                               ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "test_df['Titulo'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
    "                               ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Miss'],inplace=True)\n",
    "\n",
    "# Calculamos la edad media de cada grupo:\n",
    "mean_ages = train_df.groupby('Titulo').Age.mean().round().astype(int)\n",
    "\n",
    "# Por último, rellenamos los nulos (solo en train_df porque el test no tiene nulos en el campo Age):\n",
    "for elem in mean_ages.index:\n",
    "    train_df.loc[(train_df.Age.isnull()) & (train_df.Titulo == elem), 'Age'] = mean_ages[elem]\n",
    "    test_df.loc[(test_df.Age.isnull()) & (test_df.Titulo == elem), 'Age'] = mean_ages[elem]\n",
    "    \n",
    "# train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# C\\xc3\\xa1lculos previos:\\ntrain_df[\"Age\"] = train_df[\"Age\"].fillna(-0.5)\\ntest_df[\"Age\"] = test_df[\"Age\"].fillna(-0.5)\\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\\nlabels = [\\'Unknown\\', \\'Baby\\', \\'Child\\', \\'Teenager\\', \\'Student\\', \\'Young Adult\\', \\'Adult\\', \\'Senior\\']\\ntrain_df[\\'AgeGroup\\'] = pd.cut(train_df[\"Age\"], bins, labels = labels)\\ntest_df[\\'AgeGroup\\'] = pd.cut(test_df[\"Age\"], bins, labels = labels)\\n\\n# Sacamos el prefijo del nombre de cada persona:\\ntrain_df[\\'Titulo\\'] = train_df.Name.str.extract(\\'([A-Za-z]+)\\\\.\\', expand = False) # extraer Prefijo\\ntest_df[\\'Titulo\\'] = test_df.Name.str.extract(\\'([A-Za-z]+)\\\\.\\', expand = False) # extraer Prefijo\\n\\n# Sustituimos los prefijos mal deletreados y a\\xc3\\xb1adimos alguno:\\n# Train\\ntrain_df[\\'Titulo\\'].replace([\\'Lady\\', \\'Capt\\', \\'Col\\', \\'Dr\\', \\'Major\\', \\'Rev\\',\\n   \\'Jonkheer\\', \\'Dona\\'], \\'Other\\', inplace = True)\\ntrain_df[\\'Titulo\\'].replace(\\'Don\\', \\'Mr\\', inplace = True)    \\ntrain_df[\\'Titulo\\'].replace([\\'Countess\\', \\'Lady\\', \\'Sir\\'], \\'Royal\\', inplace = True)\\ntrain_df[\\'Titulo\\'].replace([\\'Mlle\\', \\'Ms\\'], \\'Miss\\', inplace = True)\\ntrain_df[\\'Titulo\\'].replace(\\'Mme\\', \\'Mrs\\', inplace = True)\\n# Test\\ntest_df[\\'Titulo\\'].replace([\\'Lady\\', \\'Capt\\', \\'Col\\', \\'Dr\\', \\'Major\\', \\'Rev\\',\\n   \\'Jonkheer\\', \\'Dona\\'], \\'Other\\', inplace = True)\\ntest_df[\\'Titulo\\'].replace(\\'Don\\', \\'Mr\\', inplace = True)    \\ntest_df[\\'Titulo\\'].replace([\\'Countess\\', \\'Lady\\', \\'Sir\\'], \\'Royal\\', inplace = True)\\ntest_df[\\'Titulo\\'].replace([\\'Mlle\\', \\'Ms\\'], \\'Miss\\', inplace = True)\\ntest_df[\\'Titulo\\'].replace(\\'Mme\\', \\'Mrs\\', inplace = True)\\n\\n\\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Other\": 6}\\n\\ntrain_df[\\'Titulo\\'] = train_df.Titulo.map(title_mapping)\\ntest_df[\\'Titulo\\'] = test_df.Titulo.map(title_mapping)\\n\\nmr_age = train_df[train_df[\"Titulo\"] == 1][\"AgeGroup\"].mode() #Young Adult\\nmiss_age = train_df[train_df[\"Titulo\"] == 2][\"AgeGroup\"].mode() #Student\\nmrs_age = train_df[train_df[\"Titulo\"] == 3][\"AgeGroup\"].mode() #Adult\\nmaster_age = train_df[train_df[\"Titulo\"] == 4][\"AgeGroup\"].mode() #Baby\\nroyal_age = train_df[train_df[\"Titulo\"] == 5][\"AgeGroup\"].mode() #Adult\\nrare_age = train_df[train_df[\"Titulo\"] == 6][\"AgeGroup\"].mode() #Adult\\n\\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\\n\\ntrain_df.loc[train_df.AgeGroup == \\'Unknown\\', \\'AgeGroup\\'] = train_df.Titulo.map(age_title_mapping)\\ntest_df.loc[test_df.AgeGroup == \\'Unknown\\', \\'AgeGroup\\'] = test_df.Titulo.map(age_title_mapping)\\n\\nage_mapping = {\\'Baby\\': 1, \\'Child\\': 2, \\'Teenager\\': 3, \\'Student\\': 4, \\'Young Adult\\': 5, \\'Adult\\': 6, \\'Senior\\': 7}\\n\\ntrain_df[\\'AgeGroup\\'] = train_df[\\'AgeGroup\\'].map(age_mapping)\\ntest_df[\\'AgeGroup\\'] = test_df[\\'AgeGroup\\'].map(age_mapping)\\n\\n# Eliminamos la edad, usaremos AgeGroup:\\ntrain_df.drop(\\'Age\\', axis = 1, inplace = True)\\ntest_df.drop(\\'Age\\', axis = 1, inplace = True)\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------- Propuesta 2 -------------------------------------\n",
    "# La dejamos comentada, solo hay que descomentarla. Hay muchas líneas de código porque hay que hacer algunos\n",
    "# cálculos previos para poder usarla correctamente. \n",
    "'''\n",
    "# Cálculos previos:\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(-0.5)\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(-0.5)\n",
    "bins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\n",
    "labels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "train_df['AgeGroup'] = pd.cut(train_df[\"Age\"], bins, labels = labels)\n",
    "test_df['AgeGroup'] = pd.cut(test_df[\"Age\"], bins, labels = labels)\n",
    "\n",
    "# Sacamos el prefijo del nombre de cada persona:\n",
    "train_df['Titulo'] = train_df.Name.str.extract('([A-Za-z]+)\\.', expand = False) # extraer Prefijo\n",
    "test_df['Titulo'] = test_df.Name.str.extract('([A-Za-z]+)\\.', expand = False) # extraer Prefijo\n",
    "\n",
    "# Sustituimos los prefijos mal deletreados y añadimos alguno:\n",
    "# Train\n",
    "train_df['Titulo'].replace(['Lady', 'Capt', 'Col', 'Dr', 'Major', 'Rev',\n",
    "   'Jonkheer', 'Dona'], 'Other', inplace = True)\n",
    "train_df['Titulo'].replace('Don', 'Mr', inplace = True)    \n",
    "train_df['Titulo'].replace(['Countess', 'Lady', 'Sir'], 'Royal', inplace = True)\n",
    "train_df['Titulo'].replace(['Mlle', 'Ms'], 'Miss', inplace = True)\n",
    "train_df['Titulo'].replace('Mme', 'Mrs', inplace = True)\n",
    "# Test\n",
    "test_df['Titulo'].replace(['Lady', 'Capt', 'Col', 'Dr', 'Major', 'Rev',\n",
    "   'Jonkheer', 'Dona'], 'Other', inplace = True)\n",
    "test_df['Titulo'].replace('Don', 'Mr', inplace = True)    \n",
    "test_df['Titulo'].replace(['Countess', 'Lady', 'Sir'], 'Royal', inplace = True)\n",
    "test_df['Titulo'].replace(['Mlle', 'Ms'], 'Miss', inplace = True)\n",
    "test_df['Titulo'].replace('Mme', 'Mrs', inplace = True)\n",
    "\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Other\": 6}\n",
    "\n",
    "train_df['Titulo'] = train_df.Titulo.map(title_mapping)\n",
    "test_df['Titulo'] = test_df.Titulo.map(title_mapping)\n",
    "\n",
    "mr_age = train_df[train_df[\"Titulo\"] == 1][\"AgeGroup\"].mode() #Young Adult\n",
    "miss_age = train_df[train_df[\"Titulo\"] == 2][\"AgeGroup\"].mode() #Student\n",
    "mrs_age = train_df[train_df[\"Titulo\"] == 3][\"AgeGroup\"].mode() #Adult\n",
    "master_age = train_df[train_df[\"Titulo\"] == 4][\"AgeGroup\"].mode() #Baby\n",
    "royal_age = train_df[train_df[\"Titulo\"] == 5][\"AgeGroup\"].mode() #Adult\n",
    "rare_age = train_df[train_df[\"Titulo\"] == 6][\"AgeGroup\"].mode() #Adult\n",
    "\n",
    "age_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n",
    "\n",
    "train_df.loc[train_df.AgeGroup == 'Unknown', 'AgeGroup'] = train_df.Titulo.map(age_title_mapping)\n",
    "test_df.loc[test_df.AgeGroup == 'Unknown', 'AgeGroup'] = test_df.Titulo.map(age_title_mapping)\n",
    "\n",
    "age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n",
    "\n",
    "train_df['AgeGroup'] = train_df['AgeGroup'].map(age_mapping)\n",
    "test_df['AgeGroup'] = test_df['AgeGroup'].map(age_mapping)\n",
    "\n",
    "# Eliminamos la edad, usaremos AgeGroup:\n",
    "train_df.drop('Age', axis = 1, inplace = True)\n",
    "test_df.drop('Age', axis = 1, inplace = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya no tenemos valores nulos en la dataframe que utlizaremos para entrenar el modelo. Vamos a limpiar el resto de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############################### Name #######################################\n",
    "############################################################################\n",
    "# Ya no nos sirve de nada, la hemos usado para arreglar la Edad pero no aporta información extra. La quitamos\n",
    "train_df.drop('Name', axis = 1, inplace = True)\n",
    "test_df.drop('Name', axis = 1, inplace = True)\n",
    "    \n",
    "############################################################################\n",
    "########################## Ticket & Passenger Id ###########################\n",
    "############################################################################\n",
    "# También las eliminamos, ya que no aportan ninguna información útil al modelo\n",
    "train_df.drop('Ticket', axis = 1, inplace = True)\n",
    "test_df.drop('Ticket', axis = 1, inplace = True)\n",
    "\n",
    "train_df.drop('PassengerId', axis = 1, inplace = True)\n",
    "test_df.drop('PassengerId', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_df['FareCat'] = pd.qcut(train_df['Fare'], 5, labels = [1, 2, 3, 4, 5])\\ntest_df['FareCat'] = pd.qcut(test_df['Fare'], 5, labels = [1, 2, 3, 4, 5])\\n\\n#drop Fare values\\ntrain_df = train.drop(['Fare'], axis = 1)\\ntest_df = test.drop(['Fare'], axis = 1)\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################\n",
    "############################### Fare #######################################\n",
    "############################################################################\n",
    "# Tenemosn un valor nulo en Fare en nuestro dataset de Test. Le asignaremos el valor de la media de su PClass\n",
    "# De nuevo, como con la edad, tenemos 2 opciones:\n",
    "#     1. Utilizamos el Fare (precio del pasaje) con valores continuos\n",
    "#     2. Creamos categorías para agrupar precios similares\n",
    "\n",
    "# ------------------------------- Propuesta 1 -------------------------------------\n",
    "p_class = test_df.loc[test_df.Fare.isnull(), 'Pclass'].values[0]\n",
    "test_df.loc[test_df.Fare.isnull(), 'Fare'] = test_df.groupby('Pclass').Fare.mean()[p_class]\n",
    "\n",
    "# ------------------------------- Propuesta 2 -------------------------------------\n",
    "# Creamos 5 categorías para el precio en función de los cuantiles:\n",
    "'''train_df['FareCat'] = pd.qcut(train_df['Fare'], 5, labels = [1, 2, 3, 4, 5])\n",
    "test_df['FareCat'] = pd.qcut(test_df['Fare'], 5, labels = [1, 2, 3, 4, 5])\n",
    "\n",
    "#drop Fare values\n",
    "train_df = train.drop(['Fare'], axis = 1)\n",
    "test_df = test.drop(['Fare'], axis = 1)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion: Machine Learning con distintos algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLega el momento de utilizar algoritmos para predecir la (no) supervivencia de nuestros pasajeros a bordo del titanic. Una libreria muy interesante de *python* en el ámbito del *Machine Learning* es **scikit-learn (sklearn)**. Esta librería contiene muchos algoritmos ya implementados, así como módulos para aplicar cambios necesarios en nuestros datos de forma más sencilla. Realizaremos la predicción usando diferentes algoritmos:\n",
    "\n",
    "* Gaussian Naive Bayes\n",
    "* Logistic Regression\n",
    "* Support Vector Machine (SVM)\n",
    "* Perceptron\n",
    "* Decision Tree Classifier\n",
    "* Random forest Classifier\n",
    "* K-Nearest Neighbors\n",
    "* Stochastic Gradient Descent\n",
    "* Gradient Boosting Classifier\n",
    "\n",
    "Como extra, realizaremos una clasificación con Gradient Boost Classifiers usando el módulo **XGBoost** para python.\n",
    "\n",
    "Antes de ponernos a utilizar lo modelos, usaremos un par de módulos de sklearn para arreglar 2 cosas:\n",
    "1. Estos algoritmos no admiten variables categóricas de tipo string. Solo admiten valores enteros o decimales. Por ello usaremos un *label encoder*. Lo que hace este label encoder básicamente es usar un diccionario para pasar nuestras variables categóricas a categorías numéricas.\n",
    "2. Dividiremos los datos en **entrenamiento** y **validación**. Esto es muy importante, ya que para calcular la precisión del modelo necesitamos unos datos para comprobar nuestras predicciones. Habitualmente, se coge un 70/80% de los datos para *entrenar* el modelo, y un 20/30% para *validar* los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parte 1: Codificar las variables categóricas\n",
    "# Creamos un clasificador para cada variable categórica a codificar. Podemos crear solo uno para todas,\n",
    "# pero entonces no nos guarda las categorías por si queremos invertir la codificación.\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "\n",
    "# La manera más rapida:\n",
    "train_df.Sex = le1.fit_transform(train_df.Sex)\n",
    "test_df.Sex = le1.transform(test_df.Sex)\n",
    "\n",
    "train_df.Embarked = le2.fit_transform(train_df.Embarked)\n",
    "test_df.Embarked = le2.transform(test_df.Embarked)\n",
    "\n",
    "train_df.Titulo = le3.fit_transform(train_df.Titulo)\n",
    "test_df.Titulo = le3.transform(test_df.Titulo)\n",
    "\n",
    "# Podemos ver las clases que contienen:\n",
    "# print list(le1.classes_)\n",
    "# print list(le2.classes_)\n",
    "\n",
    "# Parte 2: Dividir los datos en training y testing:\n",
    "predictors = train_df.drop(['Survived'], axis=1)\n",
    "target = train_df[\"Survived\"]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llega el momento de aplicar los diferentes modelos a nuestros datos y ver qué resultados obtenemos. Como hemos dicho, utilizaremos la librería sklearn de python. Previo a la aplicación de cada modelo, habrá una breve explicación de la idea fundamental de cada modelo, de su funcionamiento a nivel más básico.\n",
    "\n",
    "Antes que nada , notar que todos los algoritmos mencionados son **Algoritmos de Clasificación, no de Regresión**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo de aprendizaje supervisado trabaja con probabilidades, usando el *Teorema de Bayes*. Calcula la probabilidad de que un elemento esté en cada una de las clases que tenemos. La clase con mayor probabilidad es la que se devuelve como predicción. Este algoritmo asume que las direfentes variables no están relacionadas entre sí, que todas contribuyen de igual manera al resultado de la clasificación.\n",
    "Vamos a ver su implementación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"Gaussian Naive Bayes\": 81.22 % \n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred = gaussian.predict(x_val)\n",
    "acc_gau = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"Gaussian Naive Bayes\\\": {0} % '.format(acc_gau)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método de aprendizaje supervisado recibe su nombre de la función que utiliza en su implementación, la *función logística (logistic function)*:\n",
    "$$ f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Asigna unos pesos o coeficientes a cada una de las variables que miden su importancia a la hora de predecir el resultado. La función utilizada al final es del tipo:\n",
    "$$ P(X) = \\frac{e^{(b_0 + b_1*X)}}{1 + e^{(b_0 + b_1*X)}} $$\n",
    "\n",
    "que proporciona la probabilidad de estar en una determinada categoria. El modelo calcula los coeficientes $b_0$, $b_1$ y los ajusta a los datos para mejorar la precisión del modelo. Vamos a ver que tal funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"Logistic Regression\": 78.17 % \n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_val)\n",
    "acc_lreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"Logistic Regression\\\": {0} % '.format(acc_lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM es un algoritmo de aprendizaje supervisado para regresión/clasificación que se basa en encontrar el hiperplano que mejor divide los datos entre nuestras clases.\n",
    "![alt text](https://66.media.tumblr.com/ff709fe1c77091952fb3e3e6af91e302/tumblr_inline_o9aa8dYRkB1u37g00_540.png \"Hiperplane Example\")\n",
    "\n",
    "Los **vectores de soporte** son los más cercanos al hiperplano. Son aquellos que, de ser eliminados, cambiarían la disposición del hiperplano.\n",
    "\n",
    "Este hiperplano se escoje utilizando *márgenes*: la distancia entre el hiperplano y el punto más cercano de cada clase. Se intenta encontrar un hiperplano con los mayores márgenes posibles, para facilitar la correcta clasificación de nuevos elementos.\n",
    "\n",
    "![alt text](https://66.media.tumblr.com/7f12391977435370c1ddf4945dca0575/tumblr_inline_o9aa9nH3WQ1u37g00_540.png \"Margins Example\")\n",
    "\n",
    "Esta es la idea general que hay detrás del algoritmo. Vamos a ver como funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"SVM Classifier\": 71.07 % \n",
      "Precisión del algoritmo de clasificación \"LSVM Classifier\": 62.44 % \n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred = svc.predict(x_val)\n",
    "acc_svmc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"SVM Classifier\\\": {0} % '.format(acc_svmc)\n",
    "\n",
    "# Linear SVMC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(x_train, y_train)\n",
    "y_pred = linear_svc.predict(x_val)\n",
    "acc_lsvmc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "\n",
    "\n",
    "print 'Precisión del algoritmo de clasificación \\\"LSVM Classifier\\\": {0} % '.format(acc_lsvmc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Es un algoritmo de aprendizaje supervisado que sirve para entrenar un clasificador binario (como es nuestro caso). Mapea un vector de inputs $x$, a un valor output $f(x)$ usando la siguiente función:\n",
    "$$f(x) = \n",
    "\\begin{cases}\n",
    "1, & \\text{if } w · x + b > 0\\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "donde $w$ es un vector de pesos (mide la importancia de las diferentes variables) y $w·x = \\sum_{i = 1}^{m}w_i*x_i$ \n",
    "\n",
    "Por ejemplo, un caso de perceptrón muy básico sería:\n",
    "<img src=\"https://appliedgo.net/media/perceptron/heaviside.png\" width=\"400\" height=\"200\" />\n",
    "\n",
    "\n",
    "Veamos que tal lo hace con nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"Perceptron\": 56.35 %\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "y_pred = perceptron.predict(x_val)\n",
    "acc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"Perceptron\\\": {0} %'.format(acc_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como su nombre indica, este algoritmo de aprendizaje supervisado utiliza una estructura en forma de árbol para clasificar nuestros datos. La idea es colocar en la capa más alta del árbol (en la raíz) el **atributo** más significativo. A partir de este, se dividen los datos en dos ramas, que tendrán nuevos nodos en los que se volverán a dividir los datos en función de las demás variables o atributos. \n",
    "\n",
    "<img src=\"https://i1.wp.com/dataaspirant.com/wp-content/uploads/2017/01/Decision-tree-python.jpg?resize=350%2C200\" width=\"400\" height=\"200\" />\n",
    "\n",
    "Para más información: http://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/\n",
    "\n",
    "Veamos qué tal funcionan los árboles de decisión para nuestro Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"Decision Tree\": 76.65 %\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "decisiontree.fit(x_train, y_train)\n",
    "y_pred = decisiontree.predict(x_val)\n",
    "acc_dtree = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"Decision Tree\\\": {0} %'.format(acc_dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo de aprendizaje supervisado de la familia de los *ensembled algorithms*. Estos algoritmos son todos aquellos que combinan algoritmos más simples para enerar un modelo más robusto. En el caso de un *Random Forest* se crean y combinan un conjunto de *Decision Trees* para conseguir una predicción mejor de la que conseguiríamos con los árboles de decisión. Ejemplo:\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/ajTc5y3OqSQ/hqdefault.jpg\" width=\"400\" height=\"200\" />\n",
    "\n",
    "Random forest es uno de los algoritmos utilizados por *XGBoost* un algoritmo muy potente utilizado en ML. Vamos a ver qué tal lo hacen con nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"Random Forest\": 80.71 %\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred = randomforest.predict(x_val)\n",
    "acc_rf = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"Random Forest\\\": {0} %'.format(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo de aprendizaje supervisado, de tipo *non parametric lazy learning*. *Non parametric* significa que asume ninguna característica especial de los datos que utilizamos para entrenarlo o evaluarlo. *Lazy learning* implica que no utiliza los datos de entrenamiento para hacer una generalización. Esto quiere decir que no hay una fase de entrenamiento explícita o que esta es mínima, lo que implica que la fase de entrenamiento es muy rápida.\n",
    "\n",
    "Supongamos $k = 1$. La idea básica del algoritmo de KNN es la siguiente:\n",
    "\n",
    "1. encontrar el punto más *\"cercano\"* al punto a evaluar dentro de nuestros puntos clasificados. \n",
    "2. Una vez encontrado, se le asigna al nuevo punto el valor de este vecino que hemos encontrado. \n",
    "\n",
    "Este razonamiento suele ser válido cuando el número de puntos a evaluar muy grande: dos puntos similares tendrán la misma etiqueta en el caso general.\n",
    "\n",
    "Para el caso general, cuando $k = K$, se realiza una generalización del algoritmo anterior. Se encuentran los K vecinos más cercanos al punto a evaluar, y se asigna al punto en cuestión la etiqueta que aparezca más veces entre los vecinos encontrados. Parece lógico que la precisión del algoritmo mejora cuanto mayor es la $K$, pero también aumenta el coste computacional.\n",
    "\n",
    "<img src=\"http://www.statsoft.com/portals/0/Support/KNNOverViewImageA.jpg\" width=\"400\" height=\"200\" />\n",
    "\n",
    "Veamos que tal funciona:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"KNN\": 66.5 %\n"
     ]
    }
   ],
   "source": [
    "# KNN or k-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_val)\n",
    "acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"KNN\\\": {0} %'.format(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo de aprendizaje supervisado cuyo objetivo es minimizar una función (habitualmente llamada *loss function*). Dada una función que depende de unos determinados parámetros, *gradient descent* empieza con un set inicial de parámetros y avanza iterativamente hacia un valor de dichos parámetros que minimice la función objetivo. Esta minimización se consigue utilizando la función gradiente (derivando la función objetivo, utilizando la *pendiente*). \n",
    "\n",
    "<img src=\"https://qph.ec.quoracdn.net/main-qimg-b7a3a254830ac374818cdce3fa5a7f17\" width=\"400\" height=\"200\" />\n",
    "\n",
    "Veamos qué tal funciona:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"KNN\": 53.3 %\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "y_pred = sgd.predict(x_val)\n",
    "acc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"KNN\\\": {0} %'.format(acc_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo de aprendizaje es otro de los llamados *ensemble algorithms*. La idea detras del Gradient Boosting es la creación de muchos *weak learners*, clasificadores muy simples, que iterativamente se van juntando para mejorar las predicciones. En concreto, en este algoritmo suelen utilizarse árboles de decisión como week learners. Tiene 3 componentes principales:\n",
    "\n",
    "1. Una función de pérdida (*loss function*) a optimizar\n",
    "2. *Weak learners*\n",
    "3. Un *modelo aditivo* con el que añadir nuevos weak learners a nuestro modelo\n",
    "\n",
    "Se añade un árbol de decisión por iteración, utilizando un método de descenso del gradiente (algoritmo anterior) para minimizar la función de pérdida cuando se añade este nuevo árbol. En vez de parámetros, en cada iteración se debe añadir un árbol de decisión que, junto con los que ya tenemos en el modelo, reduzca la función de pérdida. El nuevo árbol deberá intentar *\"corregir\"* el error provocado por las predicciones de los árboles anteriores:\n",
    "\n",
    "<img src=\"http://arogozhnikov.github.io/images/gbdt_attractive_picture.png\" width=\"5000\" height=\"500\" />\n",
    "\n",
    "Esta técnica también se utiliza (combinada con Random Forest) en el algoritmo de predicción XGBoost, que se plantea como extra para este DATATHON.\n",
    "Veamos qué tal funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del algoritmo de clasificación \"Gradient Boosting\": 79.19 %\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbk = GradientBoostingClassifier()\n",
    "gbk.fit(x_train, y_train)\n",
    "y_pred = gbk.predict(x_val)\n",
    "acc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print 'Precisión del algoritmo de clasificación \\\"Gradient Boosting\\\": {0} %'.format(acc_gbk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos podido observar, hemos obtenido una idea de como entrenar y evaluar varios modelos de predicción con nuestros datos. A la hora de crear un algoritmo de Machine Learning, hay varias cosas que se deben tener en cuenta:\n",
    "\n",
    "1. Debemos intentar evitar el **overfitting**: Entrenar el modelo con los mismos datos que lo evaluamos, puede resultar en la creación de un modelo poco general, que se ajusta muy bien a éstos datos concretos pero puede fallar al extenderlo a nuevos datos (sobretodo si son muy diferentes a los actuales). Una manera de evitarlo, es hacer un **random sampling**, partir nuestros datos de manera aleatoria de varias formas diferentes y usarlos para entrenar/validar el modelo varias veces.\n",
    "\n",
    "2. Casi todos los modelos tienen parámetros (que aquí no hemos tenido en cuenta, hemos usado los definidos por defecto) que pueden ser ajustados para mejorar la predicción. Por ejemplo, en el caso del **XGBoost**, hay cerca de 20 parámetros que puden ser ajustados a voluntad y que pueden variar la calidad de la predicción.\n",
    "\n",
    "3. Hay algunos modelos que trabajan mejor con sets de datos pequeños y similares, mientras que otros tienen mejor rendimiento para sets de datos grandes y muy dispares. Un algoritmo nos puede ir muy bien para clasificar una variable que depende de pocas *features*, pero no para variables que dependen de muchas.\n",
    "\n",
    "Para hacernos una mejor idea del funcionamiento de los modelos, haremos varias particiones de los datos y calcularemos la precisión de los modelos para todas ellas. Finalmente, calcularemos una media de las puntuaciones obtenidas para poder decidir que modelo se ajusta mejor a nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model' : ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n",
    "    'Score_1': [acc_svmc, acc_knn, acc_lreg, \n",
    "              acc_rf, acc_gau, acc_perceptron,acc_lsvmc, acc_dtree,\n",
    "              acc_sgd, acc_gbk]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Haremos 20 iteraciones para todos los modelos con particiones diferentes de los datos.\n",
    "for i in range(2,20):\n",
    "    if (i // 10 > 0):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.25)\n",
    "\n",
    "    else:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.20)\n",
    "\n",
    "# acc_svmc, acc_knn, acc_lreg, acc_randomforest, acc_gau, acc_perceptron,acc_lsvmc, acc_decisiontree,acc_sgd, acc_gbk\n",
    "    # Calculamos todas las predicciones y todas las precisiones:\n",
    "    \n",
    "    # Gaussian Naive Bayes:\n",
    "    gaussian.fit(x_train, y_train)\n",
    "    y_pred = gaussian.predict(x_val)\n",
    "    acc_gau = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "\n",
    "    # Logistic regression:\n",
    "    logreg.fit(x_train, y_train)\n",
    "    y_pred = logreg.predict(x_val)\n",
    "    acc_lreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # SVMC y LSVMC:\n",
    "    svc.fit(x_train, y_train)\n",
    "    y_pred = svc.predict(x_val)\n",
    "    acc_svmc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "\n",
    "    linear_svc.fit(x_train, y_train)\n",
    "    y_pred = linear_svc.predict(x_val)\n",
    "    acc_lsvmc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Perceptron:\n",
    "    perceptron.fit(x_train, y_train)\n",
    "    y_pred = perceptron.predict(x_val)\n",
    "    acc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Decision tree:\n",
    "    decisiontree.fit(x_train, y_train)\n",
    "    y_pred = decisiontree.predict(x_val)\n",
    "    acc_dtree = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Random Forest:\n",
    "    randomforest.fit(x_train, y_train)\n",
    "    y_pred = randomforest.predict(x_val)\n",
    "    acc_rf = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # KNN:\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_val)\n",
    "    acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Gradient Descent:\n",
    "    sgd.fit(x_train, y_train)\n",
    "    y_pred = sgd.predict(x_val)\n",
    "    acc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Lo metemos todo en la DF de resultados:\n",
    "    results['Score_'+str(i)] = [acc_svmc, acc_knn, acc_lreg, \n",
    "              acc_rf, acc_gau, acc_perceptron,acc_lsvmc, acc_dtree,\n",
    "              acc_sgd, acc_gbk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez calculados todos los scores para las diferentes iteraciones, calculamos la media de las puntuaciones y ordenamos de mejor a peor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>80.825263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>80.416316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>79.494737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>79.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>77.253684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>73.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>70.820526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>70.303158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>64.698421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stochastic Gradient Descent</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>61.127895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Model       Mean\n",
       "Random Forest                                Random Forest  80.825263\n",
       "Naive Bayes                                    Naive Bayes  80.416316\n",
       "Logistic Regression                    Logistic Regression  79.494737\n",
       "Gradient Boosting Classifier  Gradient Boosting Classifier  79.190000\n",
       "Decision Tree                                Decision Tree  77.253684\n",
       "Linear SVC                                      Linear SVC  73.168947\n",
       "Support Vector Machines            Support Vector Machines  70.820526\n",
       "KNN                                                    KNN  70.303158\n",
       "Perceptron                                      Perceptron  64.698421\n",
       "Stochastic Gradient Descent    Stochastic Gradient Descent  61.127895"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index = results['Model'].values\n",
    "results['Mean'] = results.mean(axis = 1)\n",
    "conclusion = results[['Model', 'Mean']].sort_values(by = 'Mean', ascending = False)\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cosas Opcionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar varias técnicas diferentes con nuestros datos para ver si nuestras predicciones mejoran: Podemos normalizar los datos, incluir otras columnas (como ahora utilizar un booleano para las columnas que tengan muchos valores...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizar:\n",
    "train_norm = train_df.apply(lambda x: (x - np.mean(x)) / (np.std(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Haremos 20 iteraciones para todos los modelos con particiones diferentes de los datos.\n",
    "\n",
    "predictors = train_norm.drop(['Survived'], axis=1)\n",
    "target = train_df[\"Survived\"]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 12)\n",
    "\n",
    "for i in range(2,20):\n",
    "    if (i // 10 > 0):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.25)\n",
    "\n",
    "    else:\n",
    "        x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.20)\n",
    "\n",
    "# acc_svmc, acc_knn, acc_lreg, acc_randomforest, acc_gau, acc_perceptron,acc_lsvmc, acc_decisiontree,acc_sgd, acc_gbk\n",
    "    # Calculamos todas las predicciones y todas las precisiones:\n",
    "    \n",
    "    # Gaussian Naive Bayes:\n",
    "    gaussian.fit(x_train, y_train)\n",
    "    y_pred = gaussian.predict(x_val)\n",
    "    acc_gau = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "\n",
    "    # Logistic regression:\n",
    "    logreg.fit(x_train, y_train)\n",
    "    y_pred = logreg.predict(x_val)\n",
    "    acc_lreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # SVMC y LSVMC:\n",
    "    svc.fit(x_train, y_train)\n",
    "    y_pred = svc.predict(x_val)\n",
    "    acc_svmc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "\n",
    "    linear_svc.fit(x_train, y_train)\n",
    "    y_pred = linear_svc.predict(x_val)\n",
    "    acc_lsvmc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Perceptron:\n",
    "    perceptron.fit(x_train, y_train)\n",
    "    y_pred = perceptron.predict(x_val)\n",
    "    acc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Decision tree:\n",
    "    decisiontree.fit(x_train, y_train)\n",
    "    y_pred = decisiontree.predict(x_val)\n",
    "    acc_dtree = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Random Forest:\n",
    "    randomforest.fit(x_train, y_train)\n",
    "    y_pred = randomforest.predict(x_val)\n",
    "    acc_rf = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # KNN:\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_val)\n",
    "    acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Gradient Descent:\n",
    "    sgd.fit(x_train, y_train)\n",
    "    y_pred = sgd.predict(x_val)\n",
    "    acc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "    \n",
    "    # Lo metemos todo en la DF de resultados:\n",
    "    results['Score_'+str(i)] = [acc_svmc, acc_knn, acc_lreg, \n",
    "              acc_rf, acc_gau, acc_perceptron,acc_lsvmc, acc_dtree,\n",
    "              acc_sgd, acc_gbk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>81.165526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>80.317263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>79.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>78.830737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>78.750316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>KNN</td>\n",
       "      <td>78.381158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>77.487947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>76.632184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>71.220921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stochastic Gradient Descent</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>70.836895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Model       Mean\n",
       "Support Vector Machines            Support Vector Machines  81.165526\n",
       "Random Forest                                Random Forest  80.317263\n",
       "Gradient Boosting Classifier  Gradient Boosting Classifier  79.190000\n",
       "Logistic Regression                    Logistic Regression  78.830737\n",
       "Naive Bayes                                    Naive Bayes  78.750316\n",
       "KNN                                                    KNN  78.381158\n",
       "Linear SVC                                      Linear SVC  77.487947\n",
       "Decision Tree                                Decision Tree  76.632184\n",
       "Perceptron                                      Perceptron  71.220921\n",
       "Stochastic Gradient Descent    Stochastic Gradient Descent  70.836895"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index = results['Model'].values\n",
    "results['Mean'] = results.mean(axis = 1)\n",
    "conclusion = results[['Model', 'Mean']].sort_values(by = 'Mean', ascending = False)\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
